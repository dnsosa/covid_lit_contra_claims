{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6bd269-dfe3-47ea-9e6b-e0b40ea55138",
   "metadata": {},
   "source": [
    "## Implementing Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ecb2a9bb-d47e-4f23-b00b-de0d2ddf8190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/dnsosa/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "2022-11-01 17:38:02,365 : MainThread : INFO : loading projection weights from /Users/dnsosa/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\n",
      "2022-11-01 17:39:03,657 : MainThread : INFO : KeyedVectors lifecycle event {'msg': 'loaded (400000, 300) matrix of type float32 from /Users/dnsosa/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2022-11-01T17:39:03.656798', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 07:24:34) \\n[Clang 12.0.0 ]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import ssl\n",
    "import gensim.downloader as api\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "from fse import SplitIndexedList\n",
    "from fse.models import uSIF\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Load GLOVE, which is necessary for uSIF embeddings\n",
    "if not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "logging.basicConfig(format='%(asctime)s : %(threadName)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "glove = api.load(\"glove-wiki-gigaword-300\")\n",
    "\n",
    "def polarity_v_score(text: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate polarity of a sentence using Vader.\n",
    "\n",
    "    :param text: input sentence\n",
    "    :return: polarity value of sentence. Ranges from -1 (negative) to 1 (positive).\n",
    "    \"\"\"\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "    return vader.polarity_scores(text)[\"compound\"]\n",
    "\n",
    "def uSIF_similarity(row, model, s):\n",
    "    prem = row[\"sentence1\"]\n",
    "    prem_idx = s.items.index(prem)\n",
    "    hyp = row[\"sentence2\"]\n",
    "    hyp_idx = s.items.index(hyp)\n",
    "    similarity = model.sv.similarity(prem_idx, hyp_idx)\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "def calculate_polarity_similarity(df):\n",
    "    # Calculate polarity\n",
    "    df[\"s1_polarity\"] = df.apply(lambda row: polarity_v_score(row['sentence1']), axis=1)\n",
    "    df[\"s2_polarity\"] = df.apply(lambda row: polarity_v_score(row['sentence2']), axis=1)\n",
    "\n",
    "    unique_claims_set = set(list(df[\"sentence1\"]) + list(df[\"sentence2\"]))\n",
    "    s = SplitIndexedList(list(unique_claims_set))\n",
    "    print(f\"Found {len(s)} unique claims in DF\")\n",
    "\n",
    "    # Calculate similarity\n",
    "    model = uSIF(glove, workers=2, lang_freq=\"en\")\n",
    "    model.train(s)\n",
    "    \n",
    "    df[\"uSIF_similarity\"] = df.apply(lambda row: uSIF_similarity(row, model, s), axis=1)\n",
    "    return df\n",
    "    \n",
    "def classify_polarity_similarity(df_dict, val_set=\"val\"):\n",
    "    \n",
    "    feature_columns = [\"s1_polarity\", \"s2_polarity\", \"uSIF_similarity\"]\n",
    "    X = df_dict[\"train\"][feature_columns]\n",
    "    y = df_dict[\"train\"][\"label\"]\n",
    "\n",
    "    model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "    model.fit(X, y)\n",
    "    yhat = model.predict(df_dict[val_set][feature_columns])\n",
    "    print(classification_report(df_dict[val_set][\"label\"], yhat, digits=3))\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "aa1fe7c4-5cf3-4abb-a8e6-73686673d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from covid_lit_contra_claims.data.constants import *\n",
    "\n",
    "def load_roam_sep_data(roam_path):\n",
    "    label_map = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "    roam_df_list = []\n",
    "    splits = [\"Train\", \"Val\", \"Test\"]\n",
    "    for data_split in splits:\n",
    "        roam_df = pd.read_excel(roam_path, sheet_name=data_split)\n",
    "        roam_df = roam_df.drop(roam_df.columns[0], axis=1)\n",
    "        roam_df = roam_df.dropna().reset_index(drop=True)\n",
    "        roam_df = roam_df.rename(columns={\"text1\": \"sentence1\", \"text2\": \"sentence2\", \"annotation\": \"label\"})\n",
    "        roam_df = roam_df[roam_df[\"label\"].isin(label_map.keys())]\n",
    "        roam_df.replace({\"label\": label_map})\n",
    "        roam_df_list.append(roam_df)\n",
    "    \n",
    "    return roam_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fe911f86-14aa-4a90-a476-da0e7a6230c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 17:39:09,859 : MainThread : INFO : no frequency mode: using wordfreq for estimation of frequency for language: en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102 unique claims in DF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 17:39:11,273 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2022-11-01 17:39:11,274 : MainThread : INFO : finished scanning 102 sentences with an average length of 33 and 3428 total words\n",
      "2022-11-01 17:39:11,566 : MainThread : INFO : estimated memory for 102 sentences with 300 dimensions and 400000 vocabulary: 459 MB (0 GB)\n",
      "2022-11-01 17:39:11,569 : MainThread : INFO : initializing sentence vectors for 102 sentences\n",
      "2022-11-01 17:39:11,571 : MainThread : INFO : pre-computing uSIF weights for 400000 words\n",
      "2022-11-01 17:39:12,689 : MainThread : INFO : begin training\n",
      "2022-11-01 17:39:12,693 : MainThread : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-11-01 17:39:12,694 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-11-01 17:39:12,703 : MainThread : INFO : computing 5 principal components took 0s\n",
      "2022-11-01 17:39:12,705 : MainThread : INFO : removing 5 principal components took 0s\n",
      "2022-11-01 17:39:12,705 : MainThread : INFO : training on 102 effective sentences with 2814 effective words took 0s with 16604 sentences/s\n",
      "2022-11-01 17:39:14,512 : MainThread : INFO : no frequency mode: using wordfreq for estimation of frequency for language: en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 unique claims in DF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 17:39:15,733 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2022-11-01 17:39:15,733 : MainThread : INFO : finished scanning 48 sentences with an average length of 34 and 1653 total words\n",
      "2022-11-01 17:39:16,017 : MainThread : INFO : estimated memory for 48 sentences with 300 dimensions and 400000 vocabulary: 459 MB (0 GB)\n",
      "2022-11-01 17:39:16,018 : MainThread : INFO : initializing sentence vectors for 48 sentences\n",
      "2022-11-01 17:39:16,019 : MainThread : INFO : pre-computing uSIF weights for 400000 words\n",
      "2022-11-01 17:39:17,106 : MainThread : INFO : begin training\n",
      "2022-11-01 17:39:17,109 : MainThread : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-11-01 17:39:17,109 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-11-01 17:39:17,114 : MainThread : INFO : computing 5 principal components took 0s\n",
      "2022-11-01 17:39:17,115 : MainThread : INFO : removing 5 principal components took 0s\n",
      "2022-11-01 17:39:17,116 : MainThread : INFO : training on 48 effective sentences with 1381 effective words took 0s with 12674 sentences/s\n",
      "2022-11-01 17:39:19,344 : MainThread : INFO : no frequency mode: using wordfreq for estimation of frequency for language: en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 unique claims in DF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 17:39:20,569 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2022-11-01 17:39:20,569 : MainThread : INFO : finished scanning 54 sentences with an average length of 36 and 1997 total words\n",
      "2022-11-01 17:39:20,843 : MainThread : INFO : estimated memory for 54 sentences with 300 dimensions and 400000 vocabulary: 459 MB (0 GB)\n",
      "2022-11-01 17:39:20,844 : MainThread : INFO : initializing sentence vectors for 54 sentences\n",
      "2022-11-01 17:39:20,845 : MainThread : INFO : pre-computing uSIF weights for 400000 words\n",
      "2022-11-01 17:39:21,947 : MainThread : INFO : begin training\n",
      "2022-11-01 17:39:21,948 : MainThread : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-11-01 17:39:21,949 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-11-01 17:39:21,952 : MainThread : INFO : computing 5 principal components took 0s\n",
      "2022-11-01 17:39:21,953 : MainThread : INFO : removing 5 principal components took 0s\n",
      "2022-11-01 17:39:21,954 : MainThread : INFO : training on 54 effective sentences with 1730 effective words took 0s with 19087 sentences/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction      0.000     0.000     0.000        21\n",
      "   entailment      0.480     0.182     0.264        66\n",
      "      neutral      0.543     0.880     0.672       100\n",
      "\n",
      "     accuracy                          0.535       187\n",
      "    macro avg      0.341     0.354     0.312       187\n",
      " weighted avg      0.460     0.535     0.452       187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dnsosa/opt/miniconda3/envs/cc37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dnsosa/opt/miniconda3/envs/cc37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dnsosa/opt/miniconda3/envs/cc37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "roam_df_list = load_roam_sep_data(ROAM_SEP_PATH)\n",
    "roam_df_list_polsim = [calculate_polarity_similarity(roam_df_split) for roam_df_split in roam_df_list]\n",
    "roam_df_dict = dict(zip([\"train\", \"val\", \"test\"], roam_df_list_polsim))\n",
    "classify_polarity_similarity(roam_df_dict, val_set=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "630737bd-d370-40bb-98a1-a72a7be2978c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>s1_polarity</th>\n",
       "      <th>s2_polarity</th>\n",
       "      <th>uSIF_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>to date, only remdesivir and dexamethasone hav...</td>\n",
       "      <td>hydroxychloroquine was administered relatively...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>0.381222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>to date, only remdesivir and dexamethasone hav...</td>\n",
       "      <td>in short, neither dexamethasone nor hydrocorti...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.178178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>these findings formed the basis of a recent ra...</td>\n",
       "      <td>in moderate to severe ards covid-19 patients, ...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.7425</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.287450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>these findings formed the basis of a recent ra...</td>\n",
       "      <td>cao and co-workers showed 199 adult patients w...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.7425</td>\n",
       "      <td>-0.8625</td>\n",
       "      <td>0.164452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>these findings formed the basis of a recent ra...</td>\n",
       "      <td>the third patient, who had started receiving h...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.7425</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>0.231615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>it is important to underline that the immunomo...</td>\n",
       "      <td>in short, neither dexamethasone nor hydrocorti...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.8627</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.211342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>it is important to underline that the immunomo...</td>\n",
       "      <td>withaferin a alone or in combination with drug...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.8627</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>0.446460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>the third patient, who had started receiving h...</td>\n",
       "      <td>lopinavir-ritonavir and ribavirin have been us...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.391408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>in the  novel coronavirus pneumonia diagnosis ...</td>\n",
       "      <td>few drugs like remdesivir and dexamethasone ha...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.142546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>in the  novel coronavirus pneumonia diagnosis ...</td>\n",
       "      <td>the most prominent finding to emerge from this...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.172027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>furthermore, despite the favorable outcomes of...</td>\n",
       "      <td>however, dexamethasone is associated with incr...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.7144</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>0.455455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>specific therapeutic procedures suggested to i...</td>\n",
       "      <td>hydroxychloroquine was administered relatively...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.8316</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>0.261933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>specific therapeutic procedures suggested to i...</td>\n",
       "      <td>as very recent studies conducted on remdesivir...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.8316</td>\n",
       "      <td>-0.6969</td>\n",
       "      <td>0.286141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>in this limited case series, patients with ris...</td>\n",
       "      <td>however, dexamethasone is associated with incr...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>0.280211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>given the recent discovery that immunosuppress...</td>\n",
       "      <td>however, dexamethasone is associated with incr...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.7906</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>0.397369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>15, 16 dexamethasone is a synthetic adrenal co...</td>\n",
       "      <td>this hypothesis would caution against extrapol...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.088858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>broad-spectrum antiviral like remdisivir, chlo...</td>\n",
       "      <td>in moderate to severe ards covid-19 patients, ...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.203564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>for nucleic acid testing, sputum specimens are...</td>\n",
       "      <td>compared to other antivirals, the use of lopin...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>0.222402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>in short, neither dexamethasone nor hydrocorti...</td>\n",
       "      <td>furthermore, the administration of tocilizumab...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>0.069485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>in short, neither dexamethasone nor hydrocorti...</td>\n",
       "      <td>the presented molecular analysis of the bindin...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.191983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>in short, neither dexamethasone nor hydrocorti...</td>\n",
       "      <td>withaferin a alone or in combination with drug...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>0.134500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>however, all these changes were hospital-speci...</td>\n",
       "      <td>this hypothesis would caution against extrapol...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.095499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>however, all these changes were hospital-speci...</td>\n",
       "      <td>before the completion of the trial, many covid...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0.492336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>remdesivir, lopinavir, ritonavir, and oseltami...</td>\n",
       "      <td>as very recent studies conducted on remdesivir...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>-0.6969</td>\n",
       "      <td>-0.056636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>remdesivir, lopinavir, ritonavir, and oseltami...</td>\n",
       "      <td>compared to other antivirals, the use of lopin...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>0.084745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>conclusion this study revealed the beneficial ...</td>\n",
       "      <td>compared to other antivirals, the use of lopin...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>0.343298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>few drugs like remdesivir and dexamethasone ha...</td>\n",
       "      <td>as very recent studies conducted on remdesivir...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>-0.6969</td>\n",
       "      <td>0.484604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>few drugs like remdesivir and dexamethasone ha...</td>\n",
       "      <td>hydroxychloroquine was administered relatively...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>0.431037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>expectation mainly comes from evidences that r...</td>\n",
       "      <td>as very recent studies conducted on remdesivir...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>-0.6969</td>\n",
       "      <td>0.482213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>expectation mainly comes from evidences that r...</td>\n",
       "      <td>hydroxychloroquine was administered relatively...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>0.274263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>as very recent studies conducted on remdesivir...</td>\n",
       "      <td>arabi and colleagues initiated a placebo-contr...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.6969</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.238886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>as very recent studies conducted on remdesivir...</td>\n",
       "      <td>in addition, a case report showed that remdesi...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.6969</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>0.481093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>as very recent studies conducted on remdesivir...</td>\n",
       "      <td>we present the current evidence for the use of...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.6969</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.222949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>however, dexamethasone is associated with incr...</td>\n",
       "      <td>in the dexamethasone group, the incidence of d...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>0.196072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>however, dexamethasone is associated with incr...</td>\n",
       "      <td>recently, it was found that dexamethasone (glu...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0.399598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>however, dexamethasone is associated with incr...</td>\n",
       "      <td>17 showed that early therapy with dexamethason...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.392827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>in a historical control study, 31 the combinat...</td>\n",
       "      <td>here, the higher hr is, the more likely to dis...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>0.278426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>we present the current evidence for the use of...</td>\n",
       "      <td>hydroxychloroquine was administered relatively...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>0.149444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>in moderate to severe ards covid-19 patients, ...</td>\n",
       "      <td>these results suggest that nelfinavir, lopinav...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.297818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>the presented molecular analysis of the bindin...</td>\n",
       "      <td>before the completion of the trial, many covid...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0.231333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence1  \\\n",
       "8    to date, only remdesivir and dexamethasone hav...   \n",
       "12   to date, only remdesivir and dexamethasone hav...   \n",
       "26   these findings formed the basis of a recent ra...   \n",
       "33   these findings formed the basis of a recent ra...   \n",
       "37   these findings formed the basis of a recent ra...   \n",
       "62   it is important to underline that the immunomo...   \n",
       "66   it is important to underline that the immunomo...   \n",
       "83   the third patient, who had started receiving h...   \n",
       "97   in the  novel coronavirus pneumonia diagnosis ...   \n",
       "110  in the  novel coronavirus pneumonia diagnosis ...   \n",
       "146  furthermore, despite the favorable outcomes of...   \n",
       "185  specific therapeutic procedures suggested to i...   \n",
       "186  specific therapeutic procedures suggested to i...   \n",
       "198  in this limited case series, patients with ris...   \n",
       "208  given the recent discovery that immunosuppress...   \n",
       "221  15, 16 dexamethasone is a synthetic adrenal co...   \n",
       "227  broad-spectrum antiviral like remdisivir, chlo...   \n",
       "239  for nucleic acid testing, sputum specimens are...   \n",
       "244  in short, neither dexamethasone nor hydrocorti...   \n",
       "245  in short, neither dexamethasone nor hydrocorti...   \n",
       "248  in short, neither dexamethasone nor hydrocorti...   \n",
       "272  however, all these changes were hospital-speci...   \n",
       "273  however, all these changes were hospital-speci...   \n",
       "283  remdesivir, lopinavir, ritonavir, and oseltami...   \n",
       "284  remdesivir, lopinavir, ritonavir, and oseltami...   \n",
       "297  conclusion this study revealed the beneficial ...   \n",
       "306  few drugs like remdesivir and dexamethasone ha...   \n",
       "308  few drugs like remdesivir and dexamethasone ha...   \n",
       "316  expectation mainly comes from evidences that r...   \n",
       "320  expectation mainly comes from evidences that r...   \n",
       "331  as very recent studies conducted on remdesivir...   \n",
       "333  as very recent studies conducted on remdesivir...   \n",
       "336  as very recent studies conducted on remdesivir...   \n",
       "356  however, dexamethasone is associated with incr...   \n",
       "358  however, dexamethasone is associated with incr...   \n",
       "360  however, dexamethasone is associated with incr...   \n",
       "378  in a historical control study, 31 the combinat...   \n",
       "388  we present the current evidence for the use of...   \n",
       "401  in moderate to severe ards covid-19 patients, ...   \n",
       "419  the presented molecular analysis of the bindin...   \n",
       "\n",
       "                                             sentence2          label  \\\n",
       "8    hydroxychloroquine was administered relatively...  contradiction   \n",
       "12   in short, neither dexamethasone nor hydrocorti...  contradiction   \n",
       "26   in moderate to severe ards covid-19 patients, ...  contradiction   \n",
       "33   cao and co-workers showed 199 adult patients w...  contradiction   \n",
       "37   the third patient, who had started receiving h...  contradiction   \n",
       "62   in short, neither dexamethasone nor hydrocorti...  contradiction   \n",
       "66   withaferin a alone or in combination with drug...  contradiction   \n",
       "83   lopinavir-ritonavir and ribavirin have been us...  contradiction   \n",
       "97   few drugs like remdesivir and dexamethasone ha...  contradiction   \n",
       "110  the most prominent finding to emerge from this...  contradiction   \n",
       "146  however, dexamethasone is associated with incr...  contradiction   \n",
       "185  hydroxychloroquine was administered relatively...  contradiction   \n",
       "186  as very recent studies conducted on remdesivir...  contradiction   \n",
       "198  however, dexamethasone is associated with incr...  contradiction   \n",
       "208  however, dexamethasone is associated with incr...  contradiction   \n",
       "221  this hypothesis would caution against extrapol...  contradiction   \n",
       "227  in moderate to severe ards covid-19 patients, ...  contradiction   \n",
       "239  compared to other antivirals, the use of lopin...  contradiction   \n",
       "244  furthermore, the administration of tocilizumab...  contradiction   \n",
       "245  the presented molecular analysis of the bindin...  contradiction   \n",
       "248  withaferin a alone or in combination with drug...  contradiction   \n",
       "272  this hypothesis would caution against extrapol...  contradiction   \n",
       "273  before the completion of the trial, many covid...  contradiction   \n",
       "283  as very recent studies conducted on remdesivir...  contradiction   \n",
       "284  compared to other antivirals, the use of lopin...  contradiction   \n",
       "297  compared to other antivirals, the use of lopin...  contradiction   \n",
       "306  as very recent studies conducted on remdesivir...  contradiction   \n",
       "308  hydroxychloroquine was administered relatively...  contradiction   \n",
       "316  as very recent studies conducted on remdesivir...  contradiction   \n",
       "320  hydroxychloroquine was administered relatively...  contradiction   \n",
       "331  arabi and colleagues initiated a placebo-contr...  contradiction   \n",
       "333  in addition, a case report showed that remdesi...  contradiction   \n",
       "336  we present the current evidence for the use of...  contradiction   \n",
       "356  in the dexamethasone group, the incidence of d...  contradiction   \n",
       "358  recently, it was found that dexamethasone (glu...  contradiction   \n",
       "360  17 showed that early therapy with dexamethason...  contradiction   \n",
       "378  here, the higher hr is, the more likely to dis...  contradiction   \n",
       "388  hydroxychloroquine was administered relatively...  contradiction   \n",
       "401  these results suggest that nelfinavir, lopinav...  contradiction   \n",
       "419  before the completion of the trial, many covid...  contradiction   \n",
       "\n",
       "     s1_polarity  s2_polarity  uSIF_similarity  \n",
       "8         0.5574      -0.3412         0.381222  \n",
       "12        0.5574       0.7351         0.178178  \n",
       "26        0.7425      -0.1280         0.287450  \n",
       "33        0.7425      -0.8625         0.164452  \n",
       "37        0.7425      -0.3182         0.231615  \n",
       "62        0.8627       0.7351         0.211342  \n",
       "66        0.8627      -0.3182         0.446460  \n",
       "83       -0.3182       0.4939         0.391408  \n",
       "97        0.2263       0.9127         0.142546  \n",
       "110       0.2263       0.3804         0.172027  \n",
       "146      -0.7144      -0.4767         0.455455  \n",
       "185      -0.8316      -0.3412         0.261933  \n",
       "186      -0.8316      -0.6969         0.286141  \n",
       "198      -0.4767      -0.4767         0.280211  \n",
       "208      -0.7906      -0.4767         0.397369  \n",
       "221       0.2732       0.3612         0.088858  \n",
       "227       0.8313      -0.1280         0.203564  \n",
       "239       0.8555      -0.2500         0.222402  \n",
       "244       0.7351      -0.4215         0.069485  \n",
       "245       0.7351       0.0258         0.191983  \n",
       "248       0.7351      -0.3182         0.134500  \n",
       "272       0.5256       0.3612         0.095499  \n",
       "273       0.5256      -0.2732         0.492336  \n",
       "283      -0.6486      -0.6969        -0.056636  \n",
       "284      -0.6486      -0.2500         0.084745  \n",
       "297       0.4404      -0.2500         0.343298  \n",
       "306       0.9127      -0.6969         0.484604  \n",
       "308       0.9127      -0.3412         0.431037  \n",
       "316       0.5256      -0.6969         0.482213  \n",
       "320       0.5256      -0.3412         0.274263  \n",
       "331      -0.6969       0.7003         0.238886  \n",
       "333      -0.6969      -0.2500         0.481093  \n",
       "336      -0.6969       0.5994         0.222949  \n",
       "356      -0.4767      -0.4404         0.196072  \n",
       "358      -0.4767      -0.2023         0.399598  \n",
       "360      -0.4767       0.2960         0.392827  \n",
       "378       0.3182      -0.2500         0.278426  \n",
       "388       0.5994      -0.3412         0.149444  \n",
       "401      -0.1280       0.4767         0.297818  \n",
       "419       0.0258      -0.2732         0.231333  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xx = roam_df_dict[\"test\"]\n",
    "#xx[xx[\"label\"] == \"contradiction\"]\n",
    "\n",
    "xx = roam_df_dict[\"train\"]\n",
    "xx[xx[\"label\"] == \"contradiction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ab4ef3f8-054d-443d-ada4-6e2cdca49d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>s1_polarity</th>\n",
       "      <th>s2_polarity</th>\n",
       "      <th>uSIF_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mortality at 28 days was significantly lower i...</td>\n",
       "      <td>finally, the most recent and promising researc...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>0.7624</td>\n",
       "      <td>0.266236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an in vitro study found that remdesivir and ch...</td>\n",
       "      <td>specific therapeutic procedures suggested to i...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>-0.8316</td>\n",
       "      <td>0.249282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>an in vitro study found that remdesivir and ch...</td>\n",
       "      <td>in the  novel coronavirus pneumonia diagnosis ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.234820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an in vitro study found that remdesivir and ch...</td>\n",
       "      <td>the most prominent finding to emerge from this...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.164445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>an in vitro study found that remdesivir and ch...</td>\n",
       "      <td>remdesivir, favipiravir, baricinitib, and anak...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>-0.6597</td>\n",
       "      <td>0.129485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  mortality at 28 days was significantly lower i...   \n",
       "1  an in vitro study found that remdesivir and ch...   \n",
       "2  an in vitro study found that remdesivir and ch...   \n",
       "3  an in vitro study found that remdesivir and ch...   \n",
       "4  an in vitro study found that remdesivir and ch...   \n",
       "\n",
       "                                           sentence2       label  s1_polarity  \\\n",
       "0  finally, the most recent and promising researc...  entailment       0.7717   \n",
       "1  specific therapeutic procedures suggested to i...  entailment      -0.2023   \n",
       "2  in the  novel coronavirus pneumonia diagnosis ...     neutral      -0.2023   \n",
       "3  the most prominent finding to emerge from this...     neutral      -0.2023   \n",
       "4  remdesivir, favipiravir, baricinitib, and anak...     neutral      -0.2023   \n",
       "\n",
       "   s2_polarity  uSIF_similarity  \n",
       "0       0.7624         0.266236  \n",
       "1      -0.8316         0.249282  \n",
       "2       0.2263         0.234820  \n",
       "3       0.3804         0.164445  \n",
       "4      -0.6597         0.129485  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0b41f4f8-c864-4b33-aca0-158d782b2912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import product\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "def classify_negative_parity(premise, hypothesis):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2809b9-b0e7-4805-913c-07ae4dd26556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from covid_lit_contra_claims.evaluation.nli_utils import glove2dict\n",
    "\n",
    "glove_lookup = glove2dict(\n",
    "    os.path.join(GLOVE_HOME, 'glove.6B.300d.txt'))\n",
    "\n",
    "def glove_leaves_phi(ex, np_func=np.mean):\n",
    "    \"\"\"\n",
    "    Represent `ex` as a combination of the vector of their words,\n",
    "    and concatenate these two combinator vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ex : NLIExample\n",
    "\n",
    "    np_func : function\n",
    "        A numpy matrix operation that can be applied columnwise,\n",
    "        like `np.mean`, `np.sum`, or `np.prod`. The requirement is that\n",
    "        the function take `axis=0` as one of its arguments (to ensure\n",
    "        columnwise combination) and that it return a vector of a\n",
    "        fixed length, no matter what the size of the tree is.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "\n",
    "    \"\"\"\n",
    "    prem_vecs = _get_tree_vecs(ex.premise, glove_lookup, np_func)\n",
    "    hyp_vecs = _get_tree_vecs(ex.hypothesis, glove_lookup, np_func)\n",
    "    return np.concatenate((prem_vecs, hyp_vecs))\n",
    "\n",
    "\n",
    "def _get_tree_vecs(text, lookup, np_func):\n",
    "    tokens = tokenizer.tokenize(text)    \n",
    "    allvecs = np.array([lookup[w] for w in tokens if w in lookup])\n",
    "    if len(allvecs) == 0:\n",
    "        dim = len(next(iter(lookup.values())))\n",
    "        feats = np.zeros(dim)\n",
    "    else:\n",
    "        feats = np_func(allvecs, axis=0)\n",
    "    return feats\n",
    "\n",
    "%%time\n",
    "_ = nli.experiment(\n",
    "    train_reader=nli.NLIReader(roam_datasets['train']),\n",
    "    phi=glove_leaves_phi,\n",
    "    train_func=fit_softmax_with_hyperparameter_search,\n",
    "    assess_reader=nli.NLIReader(roam_datasets['val']),\n",
    "    vectorize=False)  # Ask `experiment` not to featurize; we did it already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "65749d1c-0833-42a8-9073-ddc856c76db2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p9/8pp847bn49bbsx879fpbsqs00000gn/T/ipykernel_67400/378512367.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'glove' is not defined"
     ]
    }
   ],
   "source": [
    "glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d9f8f5-1882-445a-bc26-87f445a7069e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf96c094-e121-45e9-8c87-aba82a7d5d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mortality at 28 days was significantly lower i...</td>\n",
       "      <td>finally, the most recent and promising researc...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an in vitro study found that remdesivir and ch...</td>\n",
       "      <td>specific therapeutic procedures suggested to i...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>an in vitro study found that remdesivir and ch...</td>\n",
       "      <td>in the  novel coronavirus pneumonia diagnosis ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an in vitro study found that remdesivir and ch...</td>\n",
       "      <td>the most prominent finding to emerge from this...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>an in vitro study found that remdesivir and ch...</td>\n",
       "      <td>remdesivir, favipiravir, baricinitib, and anak...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>in the dexamethasone group, the incidence of d...</td>\n",
       "      <td>we recommend decreasing the dose of dexamethas...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>we report herein our experience regarding the ...</td>\n",
       "      <td>our case also suggests that a brief course of ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>qt prolongation should be considered when usin...</td>\n",
       "      <td>conclusions therapeutic regimens of ifn-  + lo...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>roads less traveled might also be considered o...</td>\n",
       "      <td>arabi and colleagues initiated a placebo-contr...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>arabi and colleagues initiated a placebo-contr...</td>\n",
       "      <td>conclusions therapeutic regimens of ifn-  + lo...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence1  \\\n",
       "0    mortality at 28 days was significantly lower i...   \n",
       "1    an in vitro study found that remdesivir and ch...   \n",
       "2    an in vitro study found that remdesivir and ch...   \n",
       "3    an in vitro study found that remdesivir and ch...   \n",
       "4    an in vitro study found that remdesivir and ch...   \n",
       "..                                                 ...   \n",
       "429  in the dexamethasone group, the incidence of d...   \n",
       "430  we report herein our experience regarding the ...   \n",
       "431  qt prolongation should be considered when usin...   \n",
       "432  roads less traveled might also be considered o...   \n",
       "433  arabi and colleagues initiated a placebo-contr...   \n",
       "\n",
       "                                             sentence2      labels  \n",
       "0    finally, the most recent and promising researc...  entailment  \n",
       "1    specific therapeutic procedures suggested to i...  entailment  \n",
       "2    in the  novel coronavirus pneumonia diagnosis ...     neutral  \n",
       "3    the most prominent finding to emerge from this...     neutral  \n",
       "4    remdesivir, favipiravir, baricinitib, and anak...     neutral  \n",
       "..                                                 ...         ...  \n",
       "429  we recommend decreasing the dose of dexamethas...     neutral  \n",
       "430  our case also suggests that a brief course of ...     neutral  \n",
       "431  conclusions therapeutic regimens of ifn-  + lo...     neutral  \n",
       "432  arabi and colleagues initiated a placebo-contr...     neutral  \n",
       "433  conclusions therapeutic regimens of ifn-  + lo...  entailment  \n",
       "\n",
       "[434 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652b6649-9b34-446e-9ee6-baf779ae1007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fb778b-8b72-4961-ac76-d783e689eb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6b7fb4a-5205-4ab5-aeb9-0ead2e93ca30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74410959-ce42-4862-87d1-458ca763a972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6e9a1e6ac2427aae119d3b8491f6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cc69d2dab74d65a8a610ef5f72116f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset snli/plain_text (download: 90.17 MiB, generated: 65.51 MiB, post-processed: Unknown size, total: 155.68 MiB) to /Users/dnsosa/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e281bdbf086f4a5599af2f60c054dfab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe92e0bc1d304cd8a5931d1b687a5e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.26M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767c6b57fa6344e3ab2d43ec4acd7c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526f44904a3842868decb03cb557e535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.26M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset snli downloaded and prepared to /Users/dnsosa/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1ea7e5b4f84de1a42cd58f582de83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "snli = load_dataset(\"snli\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ddb967a-c191-48c6-95e9-2200a3425a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 550152\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df5339-2e4d-4bec-9927-307ad751dcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3bc529-4cc1-4e7e-b43f-8f7fc1077f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ec9692e-360d-4f7b-be1c-20cc30ec5378",
   "metadata": {},
   "source": [
    "## CS 224 NLI Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a272b866-2358-4cb3-b6a0-30a63f17d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From NLI\n",
    "# References: https://github.com/cgpotts/cs224u/blob/afd64b41f845b0f444b152d0f7acf2a45228349a/nli.py#L186\n",
    "from covid_lit_contra_claims.evaluation.nli_utils import fit_classifier_with_hyperparameter_search, glove2dict\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "# Hypothesis only benchmark\n",
    "def hypothesis_only_unigrams_phi(ex):\n",
    "    return Counter(tokenizer.tokenize(ex.hypothesis))\n",
    "\n",
    "def premise_only_unigrams_phi(ex):\n",
    "    return Counter(tokenizer.tokenize(ex.premise))\n",
    "\n",
    "def word_overlap_phi(ex):\n",
    "    words1 = {w.lower() for w in tokenizer.tokenize(ex.premise)}\n",
    "    words2 = {w.lower() for w in tokenizer.tokenize(ex.hypothesis)}\n",
    "    return Counter(words1 & words2)\n",
    "\n",
    "def word_cross_product_phi(ex):\n",
    "    words1 = [w.lower() for w in tokenizer.tokenize(ex.premise)]\n",
    "    words2 = [w.lower() for w in tokenizer.tokenize(ex.hypothesis)]\n",
    "    return Counter([(w1, w2) for w1, w2 in product(words1, words2)])\n",
    "\n",
    "\n",
    "#GLOVE_HOME = os.path.join('data', 'glove.6B')\n",
    "#glove_lookup = glove2dict(\n",
    "#    os.path.join(GLOVE_HOME, 'glove.6B.300d.txt'))\n",
    "\n",
    "def glove_leaves_phi(ex, np_func=np.mean):\n",
    "    \"\"\"\n",
    "    Represent `ex` as a combination of the vector of their words,\n",
    "    and concatenate these two combinator vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ex : NLIExample\n",
    "\n",
    "    np_func : function\n",
    "        A numpy matrix operation that can be applied columnwise,\n",
    "        like `np.mean`, `np.sum`, or `np.prod`. The requirement is that\n",
    "        the function take `axis=0` as one of its arguments (to ensure\n",
    "        columnwise combination) and that it return a vector of a\n",
    "        fixed length, no matter what the size of the tree is.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "\n",
    "    \"\"\"\n",
    "    prem_vecs = _get_tree_vecs(ex.premise, glove_lookup, np_func)\n",
    "    hyp_vecs = _get_tree_vecs(ex.hypothesis, glove_lookup, np_func)\n",
    "    return np.concatenate((prem_vecs, hyp_vecs))\n",
    "\n",
    "\n",
    "def _get_tree_vecs(text, lookup, np_func):\n",
    "    tokens = tokenizer.tokenize(text)    \n",
    "    allvecs = np.array([lookup[w] for w in tokens if w in lookup])\n",
    "    if len(allvecs) == 0:\n",
    "        dim = len(next(iter(lookup.values())))\n",
    "        feats = np.zeros(dim)\n",
    "    else:\n",
    "        feats = np_func(allvecs, axis=0)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d93c4f09-93c4-405e-9407-3abd374ec21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_softmax(X, y):\n",
    "    mod = LogisticRegression(\n",
    "        fit_intercept=True,\n",
    "        solver='liblinear',\n",
    "        multi_class='ovr')\n",
    "    mod.fit(X, y)\n",
    "    return mod\n",
    "\n",
    "def fit_softmax_with_hyperparameter_search(X, y):\n",
    "    \"\"\"\n",
    "    A MaxEnt model of dataset with hyperparameter cross-validation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2d np.array\n",
    "        The matrix of features, one example per row.\n",
    "\n",
    "    y : list\n",
    "        The list of labels for rows in `X`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sklearn.linear_model.LogisticRegression\n",
    "        A trained model instance, the best model found.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    mod = LogisticRegression(\n",
    "        fit_intercept=True,\n",
    "        max_iter=5,  ## A small number of iterations.\n",
    "        solver='liblinear',\n",
    "        multi_class='ovr')\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.4, 0.6, 0.8, 1.0],\n",
    "        'penalty': ['l1','l2']}\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        bestmod = fit_classifier_with_hyperparameter_search(\n",
    "            X, y, mod, param_grid=param_grid, cv=3)\n",
    "\n",
    "    return bestmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bcf96c57-5184-4391-8884-425eaf6c8e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_baseline_metrics(dataset, baseline_classifier, hp_opt=False, val_set=\"val\"):\n",
    "    \n",
    "    if hp_opt:\n",
    "        baseline_classifier_experiment_xval = nli.experiment(\n",
    "            train_reader=nli.NLIReader(dataset['train']),\n",
    "            phi=baseline_classifier,\n",
    "            train_func=fit_softmax_with_hyperparameter_search,\n",
    "            assess_reader=None,\n",
    "            verbose=False)\n",
    "\n",
    "        optimized_baseline_classifier = baseline_classifier_experiment_xval['model']\n",
    "        del baseline_classifier_experiment_xval\n",
    "\n",
    "        def fit_optimized_baseline_classifier(X, y):\n",
    "            optimized_baseline_classifier.max_iter = 1000 # To convergence in this phase!\n",
    "            optimized_baseline_classifier.fit(X, y)\n",
    "            return optimized_baseline_classifier\n",
    "        \n",
    "    \n",
    "        train_func = fit_optimized_baseline_classifier\n",
    "        \n",
    "    else: \n",
    "        train_func = fit_softmax\n",
    "    \n",
    "    baseline_results = nli.experiment(train_reader=nli.NLIReader(dataset['train']),\n",
    "                                      phi=baseline_classifier,\n",
    "                                      train_func=train_func,\n",
    "                                      assess_reader=nli.NLIReader(dataset[val_set]))\n",
    "\n",
    "    return baseline_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c4297e-e293-4962-9923-eacd53566442",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8d0f3082-e2af-4fdc-a579-a4ef84543221",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f7155c3b124bbb942589cc201cadda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0e4fda2a48409c9b7440c426beac08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b18872a7400490c87ea7b842dc6fba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115b597ee0dd405e87975cdf1e1265ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd6b4acad4f4ff08f92f77a51023f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34b76ca7c6a4d5ca6ea4874524d2c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 495 ms, sys: 38.2 ms, total: 533 ms\n",
      "Wall time: 549 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from datasets import load_dataset\n",
    "from covid_lit_contra_claims.evaluation import nli\n",
    "\n",
    "from covid_lit_contra_claims.data.CreateDatasetUtilities import load_roam_full_data\n",
    "from covid_lit_contra_claims.data.CreateDataset import create_roam_dataset\n",
    "from covid_lit_contra_claims.data.constants import *\n",
    "\n",
    "roam_dataset = create_roam_dataset(ROAM_SEP_PATH)\n",
    "roam_dataset = roam_dataset.rename_column(\"labels\", \"label\")\n",
    "roam_dataset = roam_dataset.rename_column(\"sentence1\", \"premise\")\n",
    "roam_dataset = roam_dataset.rename_column(\"sentence2\", \"hypothesis\")\n",
    "\n",
    "# snli = load_dataset(\"snli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826c6cd-e5ab-49ac-88d5-de7bc3c1b030",
   "metadata": {},
   "source": [
    "### Word Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f0398356-bd67-461e-8722-f480f762a144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 1.0, 'penalty': 'l2'}\n",
      "Best score: 0.387\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction      0.000     0.000     0.000        21\n",
      "   entailment      0.455     0.303     0.364        66\n",
      "      neutral      0.563     0.800     0.661       100\n",
      "\n",
      "     accuracy                          0.535       187\n",
      "    macro avg      0.339     0.368     0.342       187\n",
      " weighted avg      0.462     0.535     0.482       187\n",
      "\n",
      "CPU times: user 413 ms, sys: 148 ms, total: 561 ms\n",
      "Wall time: 818 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_overlap_results = calculate_baseline_metrics(roam_dataset, word_overlap_phi, hp_opt=True, val_set=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67cfe7-dc87-4e55-bfc9-b42a1cbd9805",
   "metadata": {},
   "source": [
    "### Word Cross-Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "642b7ca4-abf9-4acf-9482-4c8122a5768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 1.0, 'penalty': 'l1'}\n",
      "Best score: 0.559\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction      0.167     0.048     0.074        21\n",
      "   entailment      0.360     0.545     0.434        66\n",
      "      neutral      0.531     0.430     0.475       100\n",
      "\n",
      "     accuracy                          0.428       187\n",
      "    macro avg      0.353     0.341     0.328       187\n",
      " weighted avg      0.430     0.428     0.415       187\n",
      "\n",
      "CPU times: user 26.2 s, sys: 946 ms, total: 27.1 s\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_cross_product_results = calculate_baseline_metrics(roam_dataset, word_cross_product_phi, hp_opt=True, val_set=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43852cc2-c818-4844-b511-cf30cb18efba",
   "metadata": {},
   "source": [
    "### Hypothesis- and Premise-Only Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7d47235a-954f-434e-bedb-1c4d2c29dddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction      0.000     0.000     0.000        21\n",
      "   entailment      0.340     0.258     0.293        66\n",
      "      neutral      0.537     0.720     0.615       100\n",
      "\n",
      "     accuracy                          0.476       187\n",
      "    macro avg      0.292     0.326     0.303       187\n",
      " weighted avg      0.407     0.476     0.433       187\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction      0.000     0.000     0.000        21\n",
      "   entailment      0.333     0.439     0.379        66\n",
      "      neutral      0.510     0.510     0.510       100\n",
      "\n",
      "     accuracy                          0.428       187\n",
      "    macro avg      0.281     0.316     0.296       187\n",
      " weighted avg      0.390     0.428     0.407       187\n",
      "\n",
      "CPU times: user 239 ms, sys: 6.83 ms, total: 246 ms\n",
      "Wall time: 248 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dnsosa/opt/miniconda3/envs/cc37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dnsosa/opt/miniconda3/envs/cc37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dnsosa/opt/miniconda3/envs/cc37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hypothesis_unigrams_results = calculate_baseline_metrics(roam_dataset, hypothesis_only_unigrams_phi, hp_opt=False, val_set=\"test\")\n",
    "premise_unigrams_results = calculate_baseline_metrics(roam_dataset, premise_only_unigrams_phi, hp_opt=False, val_set=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc29567-f230-4f2a-8a81-1b3e12307c43",
   "metadata": {},
   "source": [
    "### Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa1ef2-7f6e-4a54-bf92-237e0ee3e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%%time\n",
    "_ = nli.experiment(\n",
    "    train_reader=nli.NLIReader(roam_datasets['train']),\n",
    "    phi=glove_leaves_phi,\n",
    "    train_func=fit_softmax_with_hyperparameter_search,\n",
    "    assess_reader=nli.NLIReader(roam_datasets['val']),\n",
    "    vectorize=False)  # Ask `experiment` not to featurize; we did it already."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc37",
   "language": "python",
   "name": "cc37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
