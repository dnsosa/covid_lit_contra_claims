{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6bd269-dfe3-47ea-9e6b-e0b40ea55138",
   "metadata": {},
   "source": [
    "## Implementing Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecb2a9bb-d47e-4f23-b00b-de0d2ddf8190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import ssl\n",
    "#import gensim.downloader as api\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "#from fse import SplitIndexedList\n",
    "#from fse.models import uSIF\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#from textblob import TextBlob\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "#from torch_model_base import TorchModelBase\n",
    "#from torch_rnn_classifier import TorchRNNClassifier, TorchRNNModel\n",
    "#from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "\n",
    "#import nli\n",
    "#import utils\n",
    "\n",
    "\n",
    "def classify_polarity_similarity(df):\n",
    "    # Load GLOVE, which is necessary for uSIF embeddings\n",
    "    if not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "    logging.basicConfig(format='%(asctime)s : %(threadName)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    glove = api.load(\"glove-wiki-gigaword-300\")\n",
    "\n",
    "    s = SplitIndexedList(input_claims)\n",
    "    # print(len(s))\n",
    "    # NOTE, MANY repeats\n",
    "\n",
    "    # Train the uSIF model\n",
    "    model = uSIF(glove, workers=2, lang_freq=\"en\")\n",
    "    model.train(s)\n",
    "    res_list = model.sv.similar_by_sentence(topic.split(), model=model, indexable=s.items, topn=50)\n",
    "    results = list(zip(*res_list))\n",
    "    d = {'claim': results[0], 'similarity_to_topic': results[2], 'drug': [drug] * len(results[0]),\n",
    "         'topic': [topic] * len(results[0])}\n",
    "\n",
    "    \n",
    "    all_claims_df[\"polarity_vader\"] = all_claims_df.apply(lambda row: polarity_v_score(row['claims']), axis=1)\n",
    "    \n",
    "    def polarity_v_score(text: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate polarity of a sentence using Vader.\n",
    "\n",
    "        :param text: input sentence\n",
    "        :return: polarity value of sentence. Ranges from -1 (negative) to 1 (positive).\n",
    "        \"\"\"\n",
    "        nltk.download('vader_lexicon')\n",
    "        vader = SentimentIntensityAnalyzer()\n",
    "        return vader.polarity_scores(text)['compound']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0b41f4f8-c864-4b33-aca0-158d782b2912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import product\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "def classify_negative_parity(premise, hypothesis):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65749d1c-0833-42a8-9073-ddc856c76db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa1fe7c4-5cf3-4abb-a8e6-73686673d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_roam_sep_data(roam_path):\n",
    "    label_map = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "    roam_df_list = []\n",
    "    splits = [\"Train\", \"Val\", \"Test\"]\n",
    "    for data_split in splits:\n",
    "        roam_df = pd.read_excel(roam_path, sheet_name=data_split)\n",
    "        roam_df = roam_df.drop(roam_df.columns[0], axis=1)\n",
    "        roam_df = roam_df.dropna().reset_index(drop=True)\n",
    "        roam_df = roam_df.rename(columns={\"text1\": \"sentence1\", \"text2\": \"sentence2\", \"annotation\": \"label\"})\n",
    "        roam_df = roam_df[roam_df[\"labels\"].isin(label_map.keys())]\n",
    "        roam_df.replace({\"label\": label_map})\n",
    "        roam_df_list.append(roam_df)\n",
    "    \n",
    "    return roam_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d9f8f5-1882-445a-bc26-87f445a7069e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf96c094-e121-45e9-8c87-aba82a7d5d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mortality at 28 days was significantly lower i...</td>\n",
       "      <td>finally, the most recent and promising researc...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an in vitro study found that remdesivir and ch...</td>\n",
       "      <td>specific therapeutic procedures suggested to i...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>an in vitro study found that remdesivir and ch...</td>\n",
       "      <td>in the  novel coronavirus pneumonia diagnosis ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an in vitro study found that remdesivir and ch...</td>\n",
       "      <td>the most prominent finding to emerge from this...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>an in vitro study found that remdesivir and ch...</td>\n",
       "      <td>remdesivir, favipiravir, baricinitib, and anak...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>in the dexamethasone group, the incidence of d...</td>\n",
       "      <td>we recommend decreasing the dose of dexamethas...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>we report herein our experience regarding the ...</td>\n",
       "      <td>our case also suggests that a brief course of ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>qt prolongation should be considered when usin...</td>\n",
       "      <td>conclusions therapeutic regimens of ifn-  + lo...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>roads less traveled might also be considered o...</td>\n",
       "      <td>arabi and colleagues initiated a placebo-contr...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>arabi and colleagues initiated a placebo-contr...</td>\n",
       "      <td>conclusions therapeutic regimens of ifn-  + lo...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence1  \\\n",
       "0    mortality at 28 days was significantly lower i...   \n",
       "1    an in vitro study found that remdesivir and ch...   \n",
       "2    an in vitro study found that remdesivir and ch...   \n",
       "3    an in vitro study found that remdesivir and ch...   \n",
       "4    an in vitro study found that remdesivir and ch...   \n",
       "..                                                 ...   \n",
       "429  in the dexamethasone group, the incidence of d...   \n",
       "430  we report herein our experience regarding the ...   \n",
       "431  qt prolongation should be considered when usin...   \n",
       "432  roads less traveled might also be considered o...   \n",
       "433  arabi and colleagues initiated a placebo-contr...   \n",
       "\n",
       "                                             sentence2      labels  \n",
       "0    finally, the most recent and promising researc...  entailment  \n",
       "1    specific therapeutic procedures suggested to i...  entailment  \n",
       "2    in the  novel coronavirus pneumonia diagnosis ...     neutral  \n",
       "3    the most prominent finding to emerge from this...     neutral  \n",
       "4    remdesivir, favipiravir, baricinitib, and anak...     neutral  \n",
       "..                                                 ...         ...  \n",
       "429  we recommend decreasing the dose of dexamethas...     neutral  \n",
       "430  our case also suggests that a brief course of ...     neutral  \n",
       "431  conclusions therapeutic regimens of ifn-  + lo...     neutral  \n",
       "432  arabi and colleagues initiated a placebo-contr...     neutral  \n",
       "433  conclusions therapeutic regimens of ifn-  + lo...  entailment  \n",
       "\n",
       "[434 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652b6649-9b34-446e-9ee6-baf779ae1007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fb778b-8b72-4961-ac76-d783e689eb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6b7fb4a-5205-4ab5-aeb9-0ead2e93ca30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74410959-ce42-4862-87d1-458ca763a972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6e9a1e6ac2427aae119d3b8491f6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cc69d2dab74d65a8a610ef5f72116f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset snli/plain_text (download: 90.17 MiB, generated: 65.51 MiB, post-processed: Unknown size, total: 155.68 MiB) to /Users/dnsosa/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e281bdbf086f4a5599af2f60c054dfab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe92e0bc1d304cd8a5931d1b687a5e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.26M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767c6b57fa6344e3ab2d43ec4acd7c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526f44904a3842868decb03cb557e535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.26M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset snli downloaded and prepared to /Users/dnsosa/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1ea7e5b4f84de1a42cd58f582de83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "snli = load_dataset(\"snli\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ddb967a-c191-48c6-95e9-2200a3425a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 550152\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df5339-2e4d-4bec-9927-307ad751dcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3bc529-4cc1-4e7e-b43f-8f7fc1077f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ec9692e-360d-4f7b-be1c-20cc30ec5378",
   "metadata": {},
   "source": [
    "## CS 224 NLI Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a272b866-2358-4cb3-b6a0-30a63f17d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From NLI\n",
    "# References: https://github.com/cgpotts/cs224u/blob/afd64b41f845b0f444b152d0f7acf2a45228349a/nli.py#L186\n",
    "from covid_lit_contra_claims.evaluation.nli_utils import fit_classifier_with_hyperparameter_search\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "# Hypothesis only benchmark\n",
    "def hypothesis_only_unigrams_phi(ex):\n",
    "    return Counter(tokenizer.tokenize(ex.hypothesis))\n",
    "\n",
    "def premise_only_unigrams_phi(ex):\n",
    "    return Counter(tokenizer.tokenize(ex.premise))\n",
    "\n",
    "def word_overlap_phi(ex):\n",
    "    words1 = [w.lower() for w in tokenizer.tokenize(ex.premise)]\n",
    "    words2 = [w.lower() for w in tokenizer.tokenize(ex.hypothesis)]\n",
    "    return Counter([(w1, w2) for w1, w2 in product(words1, words2)])\n",
    "\n",
    "def word_cross_product_phi(ex):\n",
    "    words1 = [w.lower() for w in tokenizer.tokenize(ex.premise)]\n",
    "    words2 = [w.lower() for w in tokenizer.tokenize(ex.hypothesis)]\n",
    "    return Counter([(w1, w2) for w1, w2 in product(words1, words2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d93c4f09-93c4-405e-9407-3abd374ec21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_softmax(X, y):\n",
    "    mod = LogisticRegression(\n",
    "        fit_intercept=True,\n",
    "        solver='liblinear',\n",
    "        multi_class='ovr')\n",
    "    mod.fit(X, y)\n",
    "    return mod\n",
    "\n",
    "def fit_softmax_with_hyperparameter_search(X, y):\n",
    "    \"\"\"\n",
    "    A MaxEnt model of dataset with hyperparameter cross-validation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2d np.array\n",
    "        The matrix of features, one example per row.\n",
    "\n",
    "    y : list\n",
    "        The list of labels for rows in `X`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sklearn.linear_model.LogisticRegression\n",
    "        A trained model instance, the best model found.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    mod = LogisticRegression(\n",
    "        fit_intercept=True,\n",
    "        max_iter=5,  ## A small number of iterations.\n",
    "        solver='liblinear',\n",
    "        multi_class='ovr')\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.4, 0.6, 0.8, 1.0],\n",
    "        'penalty': ['l1','l2']}\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        bestmod = fit_classifier_with_hyperparameter_search(\n",
    "            X, y, mod, param_grid=param_grid, cv=3)\n",
    "\n",
    "    return bestmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bcf96c57-5184-4391-8884-425eaf6c8e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_baseline_metrics(dataset, baseline_classifier, hp_opt=False):\n",
    "    \n",
    "    if hp_opt:\n",
    "        baseline_classifier_experiment_xval = nli.experiment(\n",
    "            train_reader=nli.NLIReader(dataset['train']),\n",
    "            phi=baseline_classifier,\n",
    "            train_func=fit_softmax_with_hyperparameter_search,\n",
    "            assess_reader=None,\n",
    "            verbose=False)\n",
    "\n",
    "        optimized_baseline_classifier = baseline_classifier_experiment_xval['model']\n",
    "\n",
    "        del baseline_classifier_experiment_xval\n",
    "\n",
    "        def fit_optimized_baseline_classifier(X, y):\n",
    "            optimized_baseline_classifier.max_iter = 1000 # To convergence in this phase!\n",
    "            optimized_baseline_classifier.fit(X, y)\n",
    "            return optimized_baseline_classifier\n",
    "        \n",
    "    \n",
    "        train_func = fit_optimized_baseline_classifier\n",
    "        \n",
    "    else: \n",
    "        train_func = fit_softmax\n",
    "    \n",
    "    baseline_results = nli.experiment(train_reader=nli.NLIReader(dataset['train']),\n",
    "                                      phi=baseline_classifier,\n",
    "                                      train_func=train_func,\n",
    "                                      assess_reader=nli.NLIReader(dataset['val']))\n",
    "\n",
    "    return baseline_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c4297e-e293-4962-9923-eacd53566442",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8d0f3082-e2af-4fdc-a579-a4ef84543221",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f7155c3b124bbb942589cc201cadda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0e4fda2a48409c9b7440c426beac08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b18872a7400490c87ea7b842dc6fba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115b597ee0dd405e87975cdf1e1265ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd6b4acad4f4ff08f92f77a51023f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34b76ca7c6a4d5ca6ea4874524d2c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 495 ms, sys: 38.2 ms, total: 533 ms\n",
      "Wall time: 549 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from datasets import load_dataset\n",
    "from covid_lit_contra_claims.evaluation import nli\n",
    "\n",
    "from covid_lit_contra_claims.data.CreateDatasetUtilities import load_roam_full_data\n",
    "from covid_lit_contra_claims.data.CreateDataset import create_roam_dataset\n",
    "from covid_lit_contra_claims.data.constants import *\n",
    "\n",
    "roam_dataset = create_roam_dataset(ROAM_SEP_PATH)\n",
    "roam_dataset = roam_dataset.rename_column(\"labels\", \"label\")\n",
    "roam_dataset = roam_dataset.rename_column(\"sentence1\", \"premise\")\n",
    "roam_dataset = roam_dataset.rename_column(\"sentence2\", \"hypothesis\")\n",
    "\n",
    "# snli = load_dataset(\"snli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826c6cd-e5ab-49ac-88d5-de7bc3c1b030",
   "metadata": {},
   "source": [
    "### Word Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f0398356-bd67-461e-8722-f480f762a144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.8, 'penalty': 'l1'}\n",
      "Best score: 0.482\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction      0.143     0.073     0.097        41\n",
      "   entailment      0.292     0.171     0.215        41\n",
      "      neutral      0.473     0.707     0.567        75\n",
      "\n",
      "     accuracy                          0.401       157\n",
      "    macro avg      0.303     0.317     0.293       157\n",
      " weighted avg      0.340     0.401     0.352       157\n",
      "\n",
      "CPU times: user 31.3 s, sys: 1.17 s, total: 32.5 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_overlap_results = calculate_baseline_metrics(roam_dataset, word_overlap_phi, hp_opt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67cfe7-dc87-4e55-bfc9-b42a1cbd9805",
   "metadata": {},
   "source": [
    "### Word Cross-Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "642b7ca4-abf9-4acf-9482-4c8122a5768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 1.0, 'penalty': 'l2'}\n",
      "Best score: 0.571\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction      0.000     0.000     0.000        41\n",
      "   entailment      0.278     0.244     0.260        41\n",
      "      neutral      0.496     0.800     0.612        75\n",
      "\n",
      "     accuracy                          0.446       157\n",
      "    macro avg      0.258     0.348     0.291       157\n",
      " weighted avg      0.309     0.446     0.360       157\n",
      "\n",
      "CPU times: user 32.8 s, sys: 680 ms, total: 33.5 s\n",
      "Wall time: 11 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dnsosa/opt/miniconda3/envs/cc37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dnsosa/opt/miniconda3/envs/cc37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dnsosa/opt/miniconda3/envs/cc37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_cross_product_results = calculate_baseline_metrics(roam_dataset, word_cross_product_phi, hp_opt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43852cc2-c818-4844-b511-cf30cb18efba",
   "metadata": {},
   "source": [
    "### Hypothesis- and Premise-Only Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7d47235a-954f-434e-bedb-1c4d2c29dddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction      0.400     0.049     0.087        41\n",
      "   entailment      0.500     0.171     0.255        41\n",
      "      neutral      0.522     0.960     0.676        75\n",
      "\n",
      "     accuracy                          0.516       157\n",
      "    macro avg      0.474     0.393     0.339       157\n",
      " weighted avg      0.484     0.516     0.412       157\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction      0.000     0.000     0.000        41\n",
      "   entailment      0.229     0.195     0.211        41\n",
      "      neutral      0.434     0.707     0.538        75\n",
      "\n",
      "     accuracy                          0.389       157\n",
      "    macro avg      0.221     0.301     0.250       157\n",
      " weighted avg      0.267     0.389     0.312       157\n",
      "\n",
      "CPU times: user 279 ms, sys: 8.27 ms, total: 287 ms\n",
      "Wall time: 288 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dnsosa/opt/miniconda3/envs/cc37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dnsosa/opt/miniconda3/envs/cc37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dnsosa/opt/miniconda3/envs/cc37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hypothesis_unigrams_results = calculate_baseline_metrics(roam_dataset, hypothesis_only_unigrams_phi, hp_opt=False)\n",
    "premise_unigrams_results = calculate_baseline_metrics(roam_dataset, premise_only_unigrams_phi, hp_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa1ef2-7f6e-4a54-bf92-237e0ee3e1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc37",
   "language": "python",
   "name": "cc37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
